{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c5071df-7b51-4cd4-ace3-0c28cea37408",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5b94cb6-b99f-4c23-8523-5c5ac8746be2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Fine-tuning LLMs\n",
    " Many LLMs are general purpose models trained on a broad range of data and use cases. This enables them to perform well in a variety of applications, as shown in previous modules. It is not uncommon though to find situations where applying a general purpose model performs unacceptably for specific dataset or use case. This often does not mean that the general purpose model is unusable. Perhaps, with some new data and additional training the model could be improved, or fine-tuned, such that it produces acceptable results for the specific use case.\n",
    " \n",
    " Fine-tuning uses a pre-trained model as a base and continues to train it with a new, task targeted dataset. Conceptually, fine-tuning leverages that which has already been learned by a model and aims to focus its learnings further for a specific task.\n",
    "\n",
    " It is important to recognize that fine-tuning is model training. The training process remains a resource intensive, and time consuming effort. Albeit fine-tuning training time is greatly shortened as a result of having started from a pre-trained model. The model training process can be accelerated through the use of tools like Microsoft's [DeepSpeed](https://github.com/microsoft/DeepSpeed).\n",
    "\n",
    " This notebook will explore how to perform fine-tuning at scale.\n",
    "\n",
    "### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n",
    "1. Prepare a novel dataset\n",
    "1. Fine-tune the `t5-small` model to classify movie reviews.\n",
    "1. Leverage DeepSpeed to enhance training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae2d796d-fe0a-4cd6-be9c-bb69e0bb3d92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assert \"gpu\" in spark.conf.get(\"spark.databricks.clusterUsageTags.sparkVersion\"), \"THIS LAB REQUIRES THAT A GPU MACHINE AND RUNTIME IS UTILIZED.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34382c23-de93-42d6-81ae-b2b2a3938faa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "288991c7-8fa1-466e-9539-c2f21af88ba3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Later sections of this notebook will leverage the DeepSpeed package. DeepSpeed has some additional dependencies that need to be installed in the Databricks environment. The dependencies vary based upon which MLR runtime is being used. The below commands add the necessary libraries accordingly. It is convenient to perform this step at the start of the Notebook to avoid future restarts of the Python kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c92405-bb05-4c8a-8557-dcdb758b60c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-10-17 14:56:28--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcurand-dev-11-7_10.2.10.50-1_amd64.deb\nResolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\nConnecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 41886196 (40M) [application/x-deb]\nSaving to: ‘/tmp/externals/cuda/libcurand-dev-11-7_10.2.10.50-1_amd64.deb’\n\n     0K .......... .......... .......... .......... ..........  0% 7.48M 5s\n    50K .......... .......... .......... .......... ..........  0% 7.73M 5s\n   100K .......... .......... .......... .......... ..........  0% 7.66M 5s\n   150K .......... .......... .......... .......... ..........  0%  242M 4s\n   200K .......... .......... .......... .......... ..........  0% 8.10M 4s\n   250K .......... .......... .......... .......... ..........  0%  224M 3s\n   300K .......... .......... .......... .......... ..........  0%  246M 3s\n   350K .......... .......... .......... .......... ..........  0%  251M 3s\n   400K .......... .......... .......... .......... ..........  1% 8.45M 3s\n   450K .......... .......... .......... .......... ..........  1%  316M 3s\n   500K .......... .......... .......... .......... ..........  1%  336M 2s\n   550K .......... .......... .......... .......... ..........  1%  249M 2s\n   600K .......... .......... .......... .......... ..........  1%  380M 2s\n   650K .......... .......... .......... .......... ..........  1%  355M 2s\n   700K .......... .......... .......... .......... ..........  1%  388M 2s\n   750K .......... .......... .......... .......... ..........  1%  360M 2s\n   800K .......... .......... .......... .......... ..........  2%  451M 2s\n   850K .......... .......... .......... .......... ..........  2% 9.41M 2s\n   900K .......... .......... .......... .......... ..........  2%  168M 2s\n   950K .......... .......... .......... .......... ..........  2%  241M 2s\n  1000K .......... .......... .......... .......... ..........  2%  378M 1s\n  1050K .......... .......... .......... .......... ..........  2%  428M 1s\n  1100K .......... .......... .......... .......... ..........  2%  340M 1s\n  1150K .......... .......... .......... .......... ..........  2%  338M 1s\n  1200K .......... .......... .......... .......... ..........  3%  377M 1s\n  1250K .......... .......... .......... .......... ..........  3%  320M 1s\n  1300K .......... .......... .......... .......... ..........  3%  360M 1s\n  1350K .......... .......... .......... .......... ..........  3%  312M 1s\n  1400K .......... .......... .......... .......... ..........  3%  274M 1s\n  1450K .......... .......... .......... .......... ..........  3%  279M 1s\n  1500K .......... .......... .......... .......... ..........  3%  265M 1s\n  1550K .......... .......... .......... .......... ..........  3%  230M 1s\n  1600K .......... .......... .......... .......... ..........  4%  273M 1s\n  1650K .......... .......... .......... .......... ..........  4%  266M 1s\n  1700K .......... .......... .......... .......... ..........  4%  244M 1s\n  1750K .......... .......... .......... .......... ..........  4% 13.4M 1s\n  1800K .......... .......... .......... .......... ..........  4%  188M 1s\n  1850K .......... .......... .......... .......... ..........  4%  325M 1s\n  1900K .......... .......... .......... .......... ..........  4%  424M 1s\n  1950K .......... .......... .......... .......... ..........  4%  354M 1s\n  2000K .......... .......... .......... .......... ..........  5%  219M 1s\n  2050K .......... .......... .......... .......... ..........  5%  434M 1s\n  2100K .......... .......... .......... .......... ..........  5%  437M 1s\n  2150K .......... .......... .......... .......... ..........  5%  390M 1s\n  2200K .......... .......... .......... .......... ..........  5%  280M 1s\n  2250K .......... .......... .......... .......... ..........  5%  361M 1s\n  2300K .......... .......... .......... .......... ..........  5%  336M 1s\n  2350K .......... .......... .......... .......... ..........  5%  272M 1s\n  2400K .......... .......... .......... .......... ..........  5%  284M 1s\n  2450K .......... .......... .......... .......... ..........  6%  256M 1s\n  2500K .......... .......... .......... .......... ..........  6%  254M 1s\n  2550K .......... .......... .......... .......... ..........  6%  244M 1s\n  2600K .......... .......... .......... .......... ..........  6%  268M 1s\n  2650K .......... .......... .......... .......... ..........  6%  275M 1s\n  2700K .......... .......... .......... .......... ..........  6%  258M 1s\n  2750K .......... .......... .......... .......... ..........  6%  223M 1s\n  2800K .......... .......... .......... .......... ..........  6%  267M 1s\n  2850K .......... .......... .......... .......... ..........  7%  255M 1s\n  2900K .......... .......... .......... .......... ..........  7%  253M 1s\n  2950K .......... .......... .......... .......... ..........  7%  277M 1s\n  3000K .......... .......... .......... .......... ..........  7%  242M 1s\n  3050K .......... .......... .......... .......... ..........  7%  250M 1s\n  3100K .......... .......... .......... .......... ..........  7%  278M 1s\n  3150K .......... .......... .......... .......... ..........  7%  250M 1s\n  3200K .......... .......... .......... .......... ..........  7%  386M 1s\n  3250K .......... .......... .......... .......... ..........  8%  360M 1s\n  3300K .......... .......... .......... .......... ..........  8%  394M 1s\n  3350K .......... .......... .......... .......... ..........  8% 38.8M 1s\n  3400K .......... .......... .......... .......... ..........  8%  242M 1s\n  3450K .......... .......... .......... .......... ..........  8%  264M 1s\n  3500K .......... .......... .......... .......... ..........  8%  256M 1s\n  3550K .......... .......... .......... .......... ..........  8%  191M 1s\n  3600K .......... .......... .......... .......... ..........  8%  226M 1s\n  3650K .......... .......... .......... .......... ..........  9%  249M 1s\n  3700K .......... .......... .......... .......... ..........  9%  391M 1s\n  3750K .......... .......... .......... .......... ..........  9%  384M 1s\n  3800K .......... .......... .......... .......... ..........  9%  368M 1s\n  3850K .......... .......... .......... .......... ..........  9%  302M 1s\n  3900K .......... .......... .......... .......... ..........  9%  289M 0s\n  3950K .......... .......... .......... .......... ..........  9%  324M 0s\n  4000K .......... .......... .......... .......... ..........  9%  303M 0s\n  4050K .......... .......... .......... .......... .......... 10%  380M 0s\n  4100K .......... .......... .......... .......... .......... 10%  364M 0s\n  4150K .......... .......... .......... .......... .......... 10%  382M 0s\n  4200K .......... .......... .......... .......... .......... 10%  282M 0s\n  4250K .......... .......... .......... .......... .......... 10%  262M 0s\n  4300K .......... .......... .......... .......... .......... 10%  170M 0s\n  4350K .......... .......... .......... .......... .......... 10%  237M 0s\n  4400K .......... .......... .......... .......... .......... 10%  266M 0s\n  4450K .......... .......... .......... .......... .......... 11%  268M 0s\n  4500K .......... .......... .......... .......... .......... 11%  274M 0s\n  4550K .......... .......... .......... .......... .......... 11%  258M 0s\n  4600K .......... .......... .......... .......... .......... 11%  266M 0s\n  4650K .......... .......... .......... .......... .......... 11%  295M 0s\n  4700K .......... .......... .......... .......... .......... 11%  294M 0s\n  4750K .......... .......... .......... .......... .......... 11%  241M 0s\n  4800K .......... .......... .......... .......... .......... 11%  287M 0s\n  4850K .......... .......... .......... .......... .......... 11%  332M 0s\n  4900K .......... .......... .......... .......... .......... 12%  381M 0s\n  4950K .......... .......... .......... .......... .......... 12% 49.2M 0s\n  5000K .......... .......... .......... .......... .......... 12%  337M 0s\n  5050K .......... .......... .......... .......... .......... 12%  264M 0s\n  5100K .......... .......... .......... .......... .......... 12%  221M 0s\n  5150K .......... .......... .......... .......... .......... 12%  295M 0s\n  5200K .......... .......... .......... .......... .......... 12%  437M 0s\n  5250K .......... .......... .......... .......... .......... 12%  359M 0s\n  5300K .......... .......... .......... .......... .......... 13%  385M 0s\n  5350K .......... .......... .......... .......... .......... 13%  299M 0s\n  5400K .......... .......... .......... .......... .......... 13%  425M 0s\n  5450K .......... .......... .......... .......... .......... 13%  331M 0s\n  5500K .......... .......... .......... .......... .......... 13%  431M 0s\n  5550K .......... .......... .......... .......... .......... 13%  249M 0s\n  5600K .......... .......... .......... .......... .......... 13%  297M 0s\n  5650K .......... .......... .......... .......... .......... 13%  270M 0s\n  5700K .......... .......... .......... .......... .......... 14%  255M 0s\n  5750K .......... .......... .......... .......... .......... 14%  243M 0s\n  5800K .......... .......... .......... .......... .......... 14%  276M 0s\n  5850K .......... .......... .......... .......... .......... 14%  225M 0s\n  5900K .......... .......... .......... .......... .......... 14%  261M 0s\n  5950K .......... .......... .......... .......... .......... 14%  209M 0s\n  6000K .......... .......... .......... .......... .......... 14%  259M 0s\n  6050K .......... .......... .......... .......... .......... 14%  241M 0s\n  6100K .......... .......... .......... .......... .......... 15%  260M 0s\n  6150K .......... .......... .......... .......... .......... 15%  200M 0s\n  6200K .......... .......... .......... .......... .......... 15%  259M 0s\n  6250K .......... .......... .......... .......... .......... 15%  218M 0s\n  6300K .......... .......... .......... .......... .......... 15%  227M 0s\n  6350K .......... .......... .......... .......... .......... 15%  220M 0s\n  6400K .......... .......... .......... .......... .......... 15%  259M 0s\n  6450K .......... .......... .......... .......... .......... 15%  241M 0s\n  6500K .......... .......... .......... .......... .......... 16%  263M 0s\n  6550K .......... .......... .......... .......... .......... 16% 52.9M 0s\n  6600K .......... .......... .......... .......... .......... 16%  416M 0s\n  6650K .......... .......... .......... .......... .......... 16%  144M 0s\n  6700K .......... .......... .......... .......... .......... 16%  348M 0s\n  6750K .......... .......... .......... .......... .......... 16%  312M 0s\n  6800K .......... .......... .......... .......... .......... 16%  366M 0s\n  6850K .......... .......... .......... .......... .......... 16%  438M 0s\n  6900K .......... .......... .......... .......... .......... 16%  309M 0s\n  6950K .......... .......... .......... .......... .......... 17%  230M 0s\n  7000K .......... .......... .......... .......... .......... 17%  276M 0s\n  7050K .......... .......... .......... .......... .......... 17%  380M 0s\n  7100K .......... .......... .......... .......... .......... 17%  289M 0s\n  7150K .......... .......... .......... .......... .......... 17%  215M 0s\n  7200K .......... .......... .......... .......... .......... 17%  311M 0s\n  7250K .......... .......... .......... .......... .......... 17%  414M 0s\n  7300K .......... .......... .......... .......... .......... 17%  328M 0s\n  7350K .......... .......... .......... .......... .......... 18%  251M 0s\n  7400K .......... .......... .......... .......... .......... 18%  359M 0s\n  7450K .......... .......... .......... .......... .......... 18%  315M 0s\n  7500K .......... .......... .......... .......... .......... 18%  282M 0s\n  7550K .......... .......... .......... .......... .......... 18%  308M 0s\n  7600K .......... .......... .......... .......... .......... 18%  374M 0s\n  7650K .......... .......... .......... .......... .......... 18%  285M 0s\n  7700K .......... .......... .......... .......... .......... 18%  326M 0s\n  7750K .......... .......... .......... .......... .......... 19%  280M 0s\n  7800K .......... .......... .......... .......... .......... 19%  361M 0s\n  7850K .......... .......... .......... .......... .......... 19%  354M 0s\n  7900K .......... .......... .......... .......... .......... 19%  369M 0s\n  7950K .......... .......... .......... .......... .......... 19%  310M 0s\n  8000K .......... .......... .......... .......... .......... 19%  299M 0s\n  8050K .......... .......... .......... .......... .......... 19%  296M 0s\n  8100K .......... .......... .......... .......... .......... 19%  313M 0s\n  8150K .......... .......... .......... .......... .......... 20% 36.8M 0s\n  8200K .......... .......... .......... .......... .......... 20%  313M 0s\n  8250K .......... .......... .......... .......... .......... 20%  128M 0s\n  8300K .......... .......... .......... .......... .......... 20%  424M 0s\n  8350K .......... .......... .......... .......... .......... 20%  350M 0s\n  8400K .......... .......... .......... .......... .......... 20%  214M 0s\n  8450K .......... .......... .......... .......... .......... 20%  313M 0s\n  8500K .......... .......... .......... .......... .......... 20%  426M 0s\n  8550K .......... .......... .......... .......... .......... 21%  344M 0s\n  8600K .......... .......... .......... .......... .......... 21%  432M 0s\n  8650K .......... .......... .......... .......... .......... 21%  374M 0s\n  8700K .......... .......... .......... .......... .......... 21%  390M 0s\n  8750K .......... .......... .......... .......... .......... 21%  338M 0s\n  8800K .......... .......... .......... .......... .......... 21%  269M 0s\n  8850K .......... .......... .......... .......... .......... 21%  353M 0s\n  8900K .......... .......... .......... .......... .......... 21%  344M 0s\n  8950K .......... .......... .......... .......... .......... 22%  226M 0s\n  9000K .......... .......... .......... .......... .......... 22%  233M 0s\n  9050K .......... .......... .......... .......... .......... 22%  242M 0s\n  9100K .......... .......... .......... .......... .......... 22%  258M 0s\n  9150K .......... .......... .......... .......... .......... 22%  262M 0s\n  9200K .......... .......... .......... .......... .......... 22%  352M 0s\n  9250K .......... .......... .......... .......... .......... 22%  231M 0s\n  9300K .......... .......... .......... .......... .......... 22%  274M 0s\n  9350K .......... .......... .......... .......... .......... 22%  310M 0s\n  9400K .......... .......... .......... .......... .......... 23%  251M 0s\n  9450K .......... .......... .......... .......... .......... 23%  249M 0s\n  9500K .......... .......... .......... .......... .......... 23%  263M 0s\n  9550K .......... .......... .......... .......... .......... 23%  231M 0s\n  9600K .......... .......... .......... .......... .......... 23%  253M 0s\n  9650K .......... .......... .......... .......... .......... 23%  263M 0s\n  9700K .......... .......... .......... .......... .......... 23%  268M 0s\n  9750K .......... .......... .......... .......... .......... 23% 59.4M 0s\n  9800K .......... .......... .......... .......... .......... 24%  120M 0s\n  9850K .......... .......... .......... .......... .......... 24%  133M 0s\n  9900K .......... .......... .......... .......... .......... 24%  219M 0s\n  9950K .......... .......... .......... .......... .......... 24%  221M 0s\n 10000K .......... .......... .......... .......... .......... 24%  319M 0s\n 10050K .......... .......... .......... .......... .......... 24%  116M 0s\n 10100K .......... .......... .......... .......... .......... 24%  225M 0s\n 10150K .......... .......... .......... .......... .......... 24%  261M 0s\n 10200K .......... .......... .......... .......... .......... 25%  183M 0s\n 10250K .......... .......... .......... .......... .......... 25%  303M 0s\n 10300K .......... .......... .......... .......... .......... 25%  234M 0s\n 10350K .......... .......... .......... .......... .......... 25%  234M 0s\n 10400K .......... .......... .......... .......... .......... 25%  297M 0s\n 10450K .......... .......... .......... .......... .......... 25%  267M 0s\n 10500K .......... .......... .......... .......... .......... 25%  281M 0s\n 10550K .......... .......... .......... .......... .......... 25%  262M 0s\n 10600K .......... .......... .......... .......... .......... 26%  271M 0s\n 10650K .......... .......... .......... .......... .......... 26%  279M 0s\n 10700K .......... .......... .......... .......... .......... 26%  242M 0s\n 10750K .......... .......... .......... .......... .......... 26%  222M 0s\n 10800K .......... .......... .......... .......... .......... 26%  285M 0s\n 10850K .......... .......... .......... .......... .......... 26%  306M 0s\n 10900K .......... .......... .......... .......... .......... 26%  262M 0s\n 10950K .......... .......... .......... .......... .......... 26%  256M 0s\n 11000K .......... .......... .......... .......... .......... 27%  278M 0s\n 11050K .......... .......... .......... .......... .......... 27%  238M 0s\n 11100K .......... .......... .......... .......... .......... 27%  264M 0s\n 11150K .......... .......... .......... .......... .......... 27%  224M 0s\n 11200K .......... .......... .......... .......... .......... 27%  287M 0s\n 11250K .......... .......... .......... .......... .......... 27%  288M 0s\n 11300K .......... .......... .......... .......... .......... 27%  256M 0s\n 11350K .......... .......... .......... .......... .......... 27%  257M 0s\n 11400K .......... .......... .......... .......... .......... 27%  246M 0s\n 11450K .......... .......... .......... .......... .......... 28%  253M 0s\n 11500K .......... .......... .......... .......... .......... 28%  260M 0s\n 11550K .......... .......... .......... .......... .......... 28%  217M 0s\n 11600K .......... .......... .......... .......... .......... 28%  289M 0s\n 11650K .......... .......... .......... .......... .......... 28%  282M 0s\n 11700K .......... .......... .......... .......... .......... 28%  257M 0s\n 11750K .......... .......... .......... .......... .......... 28%  255M 0s\n 11800K .......... .......... .......... .......... .......... 28%  270M 0s\n 11850K .......... .......... .......... .......... .......... 29%  282M 0s\n 11900K .......... .......... .......... .......... .......... 29%  305M 0s\n 11950K .......... .......... .......... .......... .......... 29%  225M 0s\n 12000K .......... .......... .......... .......... .......... 29%  224M 0s\n 12050K .......... .......... .......... .......... .......... 29%  262M 0s\n 12100K .......... .......... .......... .......... .......... 29%  252M 0s\n 12150K .......... .......... .......... .......... .......... 29%  211M 0s\n 12200K .......... .......... .......... .......... .......... 29%  274M 0s\n 12250K .......... .......... .......... .......... .......... 30%  252M 0s\n 12300K .......... .......... .......... .......... .......... 30%  280M 0s\n 12350K .......... .......... .......... .......... .......... 30%  213M 0s\n 12400K .......... .......... .......... .......... .......... 30%  286M 0s\n 12450K .......... .......... .......... .......... .......... 30%  260M 0s\n 12500K .......... .......... .......... .......... .......... 30%  304M 0s\n 12550K .......... .......... .......... .......... .......... 30%  264M 0s\n 12600K .......... .......... .......... .......... .......... 30%  271M 0s\n 12650K .......... .......... .......... .......... .......... 31%  271M 0s\n 12700K .......... .......... .......... .......... .......... 31%  256M 0s\n 12750K .......... .......... .......... .......... .......... 31%  231M 0s\n 12800K .......... .......... .......... .......... .......... 31%  256M 0s\n 12850K .......... .......... .......... .......... .......... 31%  308M 0s\n 12900K .......... .......... .......... .......... .......... 31%  304M 0s\n 12950K .......... .......... .......... .......... .......... 31%  238M 0s\n 13000K .......... .......... .......... .......... .......... 31%  288M 0s\n 13050K .......... .......... .......... .......... .......... 32%  289M 0s\n 13100K .......... .......... .......... .......... .......... 32%  306M 0s\n 13150K .......... .......... .......... .......... .......... 32% 78.6M 0s\n 13200K .......... .......... .......... .......... .......... 32%  222M 0s\n 13250K .......... .......... .......... .......... .......... 32%  217M 0s\n 13300K .......... .......... .......... .......... .......... 32%  285M 0s\n 13350K .......... .......... .......... .......... .......... 32%  262M 0s\n 13400K .......... .......... .......... .......... .......... 32%  231M 0s\n 13450K .......... .......... .......... .......... .......... 33%  269M 0s\n 13500K .......... .......... .......... .......... .......... 33%  307M 0s\n 13550K .......... .......... .......... .......... .......... 33%  211M 0s\n 13600K .......... .......... .......... .......... .......... 33%  274M 0s\n 13650K .......... .......... .......... .......... .......... 33%  267M 0s\n 13700K .......... .......... .......... .......... .......... 33%  288M 0s\n 13750K .......... .......... .......... .......... .......... 33%  287M 0s\n 13800K .......... .......... .......... .......... .......... 33%  234M 0s\n 13850K .......... .......... .......... .......... .......... 33%  251M 0s\n 13900K .......... .......... .......... .......... .......... 34%  287M 0s\n 13950K .......... .......... .......... .......... .......... 34%  277M 0s\n 14000K .......... .......... .......... .......... .......... 34%  264M 0s\n 14050K .......... .......... .......... .......... .......... 34%  286M 0s\n 14100K .......... .......... .......... .......... .......... 34%  296M 0s\n 14150K .......... .......... .......... .......... .......... 34%  230M 0s\n 14200K .......... .......... .......... .......... .......... 34%  260M 0s\n 14250K .......... .......... .......... .......... .......... 34%  246M 0s\n 14300K .......... .......... .......... .......... .......... 35%  280M 0s\n 14350K .......... .......... .......... .......... .......... 35%  223M 0s\n 14400K .......... .......... .......... .......... .......... 35%  235M 0s\n 14450K .......... .......... .......... .......... .......... 35%  288M 0s\n 14500K .......... .......... .......... .......... .......... 35%  298M 0s\n 14550K .......... .......... .......... .......... .......... 35%  285M 0s\n 14600K .......... .......... .......... .......... .......... 35%  289M 0s\n 14650K .......... .......... .......... .......... .......... 35%  263M 0s\n 14700K .......... .......... .......... .......... .......... 36%  289M 0s\n 14750K .......... .......... .......... .......... .......... 36%  243M 0s\n 14800K .......... .......... .......... .......... .......... 36%  284M 0s\n 14850K .......... .......... .......... .......... .......... 36%  192M 0s\n 14900K .......... .......... .......... .......... .......... 36%  303M 0s\n 14950K .......... .......... .......... .......... .......... 36%  285M 0s\n 15000K .......... .......... .......... .......... .......... 36%  263M 0s\n 15050K .......... .......... .......... .......... .......... 36%  274M 0s\n 15100K .......... .......... .......... .......... .......... 37%  306M 0s\n 15150K .......... .......... .......... .......... .......... 37%  208M 0s\n 15200K .......... .......... .......... .......... .......... 37%  242M 0s\n 15250K .......... .......... .......... .......... .......... 37%  278M 0s\n 15300K .......... .......... .......... .......... .......... 37%  276M 0s\n 15350K .......... .......... .......... .......... .......... 37%  277M 0s\n 15400K .......... .......... .......... .......... .......... 37%  298M 0s\n 15450K .......... .......... .......... .......... .......... 37%  236M 0s\n 15500K .......... .......... .......... .......... .......... 38%  291M 0s\n 15550K .......... .......... .......... .......... .......... 38%  242M 0s\n 15600K .......... .......... .......... .......... .......... 38%  292M 0s\n 15650K .......... .......... .......... .......... .......... 38%  275M 0s\n 15700K .......... .......... .......... .......... .......... 38%  291M 0s\n 15750K .......... .......... .......... .......... .......... 38%  293M 0s\n 15800K .......... .......... .......... .......... .......... 38%  278M 0s\n 15850K .......... .......... .......... .......... .......... 38%  302M 0s\n 15900K .......... .......... .......... .......... .......... 38%  239M 0s\n 15950K .......... .......... .......... .......... .......... 39%  216M 0s\n 16000K .......... .......... .......... .......... .......... 39%  279M 0s\n 16050K .......... .......... .......... .......... .......... 39%  268M 0s\n 16100K .......... .\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n....... 48%  264M 0s\n 15600K .......... .......... .......... .......... .......... 49%  428M 0s\n 15650K .......... .......... .......... .......... .......... 49%  329M 0s\n 15700K .......... .......... .......... .......... .......... 49%  423M 0s\n 15750K .......... .......... .......... .......... .......... 49%  326M 0s\n 15800K .......... .......... .......... .......... .......... 49%  291M 0s\n 15850K .......... .......... .......... .......... .......... 49%  363M 0s\n 15900K .......... .......... .......... .......... .......... 49%  347M 0s\n 15950K .......... .......... .......... .......... .......... 50%  328M 0s\n 16000K .......... .......... .......... .......... .......... 50%  380M 0s\n 16050K .......... .......... .......... .......... .......... 50%  351M 0s\n 16100K .......... .......... .......... .......... .......... 50%  321M 0s\n 16150K .......... .......... .......... .......... .......... 50%  390M 0s\n 16200K .......... .......... .......... .......... .......... 50%  338M 0s\n 16250K .......... .......... .......... .......... .......... 51%  364M 0s\n 16300K .......... .......... .......... .......... .......... 51%  359M 0s\n 16350K .......... .......... .......... .......... .......... 51%  332M 0s\n 16400K .......... .......... .......... .......... .......... 51%  378M 0s\n 16450K .......... .......... .......... .......... .......... 51%  371M 0s\n 16500K .......... .......... .......... .......... .......... 51% 89.4M 0s\n 16550K .......... .......... .......... .......... .......... 51%  269M 0s\n 16600K .......... .......... .......... .......... .......... 52%  359M 0s\n 16650K .......... .......... .......... .......... .......... 52%  344M 0s\n 16700K .......... .......... .......... .......... .......... 52%  179M 0s\n 16750K .......... .......... .......... .......... .......... 52%  271M 0s\n 16800K .......... .......... .......... .......... .......... 52%  340M 0s\n 16850K .......... .......... .......... .......... .......... 52%  274M 0s\n 16900K .......... .......... .......... .......... .......... 53%  427M 0s\n 16950K .......... .......... .......... .......... .......... 53%  388M 0s\n 17000K .......... .......... .......... .......... .......... 53%  336M 0s\n 17050K .......... .......... .......... .......... .......... 53%  309M 0s\n 17100K .......... .......... .......... .......... .......... 53%  432M 0s\n 17150K .......... .......... .......... .......... .......... 53%  268M 0s\n 17200K .......... .......... .......... .......... .......... 54%  367M 0s\n 17250K .......... .......... .......... .......... .......... 54%  374M 0s\n 17300K .......... .......... .......... .......... .......... 54%  404M 0s\n 17350K .......... .......... .......... .......... .......... 54%  325M 0s\n 17400K .......... .......... .......... .......... .......... 54%  420M 0s\n 17450K .......... .......... .......... .......... .......... 54%  294M 0s\n 17500K .......... .......... .......... .......... .......... 54%  370M 0s\n 17550K .......... .......... .......... .......... .......... 55%  292M 0s\n 17600K .......... .......... .......... .......... .......... 55%  364M 0s\n 17650K .......... .......... .......... .......... .......... 55%  392M 0s\n 17700K .......... .......... .......... .......... .......... 55%  351M 0s\n 17750K .......... .......... .......... .......... .......... 55%  399M 0s\n 17800K .......... .......... .......... .......... .......... 55%  429M 0s\n 17850K .......... .......... .......... .......... .......... 56%  323M 0s\n 17900K .......... .......... .......... .......... .......... 56%  180M 0s\n 17950K .......... .......... .......... .......... .......... 56%  322M 0s\n 18000K .......... .......... .......... .......... .......... 56%  381M 0s\n 18050K .......... .......... .......... .......... .......... 56%  314M 0s\n 18100K .......... .......... .......... .......... .......... 56%  249M 0s\n 18150K .......... .......... .......... .......... .......... 56% 30.0M 0s\n 18200K .......... .......... .......... .......... .......... 57%  225M 0s\n 18250K .......... .......... .......... .......... .......... 57%  268M 0s\n 18300K .......... .......... .......... .......... .......... 57%  269M 0s\n 18350K .......... .......... .......... .......... .......... 57%  152M 0s\n 18400K .......... .......... .......... .......... .......... 57%  242M 0s\n 18450K .......... .......... .......... .......... .......... 57%  366M 0s\n 18500K .......... .......... .......... .......... .......... 58%  293M 0s\n 18550K .......... .......... .......... .......... .......... 58%  325M 0s\n 18600K .......... .......... .......... .......... .......... 58%  281M 0s\n 18650K .......... .......... .......... .......... .......... 58%  352M 0s\n 18700K .......... .......... .......... .......... .......... 58%  278M 0s\n 18750K .......... .......... .......... .......... .......... 58%  356M 0s\n 18800K .......... .......... .......... .......... .......... 59%  416M 0s\n 18850K .......... .......... .......... .......... .......... 59%  372M 0s\n 18900K .......... .......... .......... .......... .......... 59%  419M 0s\n 18950K .......... .......... .......... .......... .......... 59%  313M 0s\n 19000K .......... .......... .......... .......... .......... 59%  357M 0s\n 19050K .......... .......... .......... .......... .......... 59%  367M 0s\n 19100K .......... .......... .......... .......... .......... 59%  358M 0s\n 19150K .......... .......... .......... .......... .......... 60%  320M 0s\n 19200K .......... .......... .......... .......... .......... 60%  396M 0s\n 19250K .......... .......... .......... .......... .......... 60%  224M 0s\n 19300K .......... .......... .......... .......... .......... 60%  410M 0s\n 19350K .......... .......... .......... .......... .......... 60%  276M 0s\n 19400K .......... .......... .......... .......... .......... 60%  402M 0s\n 19450K .......... .......... .......... .......... .......... 61%  327M 0s\n 19500K .......... .......... .......... .......... .......... 61%  338M 0s\n 19550K .......... .......... .......... .......... .......... 61%  319M 0s\n 19600K .......... .......... .......... .......... .......... 61%  433M 0s\n 19650K .......... .......... .......... .......... .......... 61%  332M 0s\n 19700K .......... .......... .......... .......... .......... 61%  434M 0s\n 19750K .......... .......... .......... .......... .......... 61%  279M 0s\n 19800K .......... .......... .......... .......... .......... 62% 61.3M 0s\n 19850K .......... .......... .......... .......... .......... 62% 50.9M 0s\n 19900K .......... .......... .......... .......... .......... 62%  210M 0s\n 19950K .......... .......... .......... .......... .......... 62%  155M 0s\n 20000K .......... .......... .......... .......... .......... 62%  328M 0s\n 20050K .......... .......... .......... .......... .......... 62%  170M 0s\n 20100K .......... .......... .......... .......... .......... 63%  417M 0s\n 20150K .......... .......... .......... .......... .......... 63%  291M 0s\n 20200K .......... .......... .......... .......... .......... 63%  363M 0s\n 20250K .......... .......... .......... .......... .......... 63%  233M 0s\n 20300K .......... .......... .......... .......... .......... 63%  392M 0s\n 20350K .......... .......... .......... .......... .......... 63%  193M 0s\n 20400K .......... .......... .......... .......... .......... 64%  427M 0s\n 20450K .......... .......... .......... .......... .......... 64%  434M 0s\n 20500K .......... .......... .......... .......... .......... 64%  356M 0s\n 20550K .......... .......... .......... .......... .......... 64%  296M 0s\n 20600K .......... .......... .......... .......... .......... 64%  396M 0s\n 20650K .......... .......... .......... .......... .......... 64%  329M 0s\n 20700K .......... .......... .......... .......... .......... 64%  271M 0s\n 20750K .......... .......... .......... .......... .......... 65%  337M 0s\n 20800K .......... .......... .......... .......... .......... 65%  448M 0s\n 20850K .......... .......... .......... .......... .......... 65%  398M 0s\n 20900K .......... .......... .......... .......... .......... 65%  269M 0s\n 20950K .......... .......... .......... .......... .......... 65%  330M 0s\n 21000K .......... .......... .......... .......... .......... 65%  333M 0s\n 21050K .......... .......... .......... .......... .......... 66%  393M 0s\n 21100K .......... .......... .......... .......... .......... 66%  349M 0s\n 21150K .......... .......... .......... .......... .......... 66%  286M 0s\n 21200K .......... .......... .......... .......... .......... 66%  340M 0s\n 21250K .......... .......... .......... .......... .......... 66%  401M 0s\n 21300K .......... .......... .......... .......... .......... 66%  271M 0s\n 21350K .......... .......... .......... .......... .......... 67%  333M 0s\n 21400K .......... .......... .......... .......... .......... 67%  413M 0s\n 21450K .......... .......... .......... .......... .......... 67% 66.6M 0s\n 21500K .......... .......... .......... .......... .......... 67% 57.8M 0s\n 21550K .......... .......... .......... .......... .......... 67%  246M 0s\n 21600K .......... .......... .......... .......... .......... 67%  140M 0s\n 21650K .......... .......... .......... .......... .......... 67%  279M 0s\n 21700K .......... .......... .......... .......... .......... 68%  193M 0s\n 21750K .......... .......... .......... .......... .......... 68%  381M 0s\n 21800K .......... .......... .......... .......... .......... 68%  247M 0s\n 21850K .......... .......... .......... .......... .......... 68%  367M 0s\n 21900K .......... .......... .......... .......... .......... 68%  357M 0s\n 21950K .......... .......... .......... .......... .......... 68%  180M 0s\n 22000K .......... .......... .......... .......... .......... 69%  236M 0s\n 22050K .......... .......... .......... .......... .......... 69%  370M 0s\n 22100K .......... .......... .......... .......... .......... 69%  360M 0s\n 22150K .......... .......... .......... .......... .......... 69%  300M 0s\n 22200K .......... .......... .......... .......... .......... 69%  259M 0s\n 22250K .......... .......... .......... .......... .......... 69%  342M 0s\n 22300K .......... .......... .......... .......... .......... 69%  375M 0s\n 22350K .......... .......... .......... .......... .......... 70%  259M 0s\n 22400K .......... .......... .......... .......... .......... 70%  371M 0s\n 22450K .......... .......... .......... .......... .......... 70%  437M 0s\n 22500K .......... .......... .......... .......... .......... 70%  350M 0s\n 22550K .......... .......... .......... .......... .......... 70%  343M 0s\n 22600K .......... .......... .......... .......... .......... 70%  358M 0s\n 22650K .......... .......... .......... .......... .......... 71%  333M 0s\n 22700K .......... .......... .......... .......... .......... 71%  379M 0s\n 22750K .......... .......... .......... .......... .......... 71%  332M 0s\n 22800K .......... .......... .......... .......... .......... 71%  450M 0s\n 22850K .......... .......... .......... .......... .......... 71%  308M 0s\n 22900K .......... .......... .......... .......... .......... 71%  307M 0s\n 22950K .......... .......... .......... .......... .......... 72%  313M 0s\n 23000K .......... .......... .......... .......... .......... 72%  409M 0s\n 23050K .......... .......... .......... .......... .......... 72%  460M 0s\n 23100K .......... .......... .......... .......... .......... 72% 64.6M 0s\n 23150K .......... .......... .......... .......... .......... 72% 47.3M 0s\n 23200K .......... .......... .......... .......... .......... 72%  355M 0s\n 23250K .......... .......... .......... .......... .......... 72%  283M 0s\n 23300K .......... .......... .......... .......... .......... 73%  301M 0s\n 23350K .......... .......... .......... .......... .......... 73%  132M 0s\n 23400K .......... .......... .......... .......... .......... 73%  392M 0s\n 23450K .......... .......... .......... .......... .......... 73%  407M 0s\n 23500K .......... .......... .......... .......... .......... 73%  308M 0s\n 23550K .......... .......... .......... .......... .......... 73%  330M 0s\n 23600K .......... .......... .......... .......... .......... 74%  274M 0s\n 23650K .......... .......... .......... .......... .......... 74%  264M 0s\n 23700K .......... .......... .......... .......... .......... 74%  163M 0s\n 23750K .......... .......... .......... .......... .......... 74%  367M 0s\n 23800K .......... .......... .......... .......... .......... 74%  298M 0s\n 23850K .......... .......... .......... .......... .......... 74%  432M 0s\n 23900K .......... .......... .......... .......... .......... 74%  390M 0s\n 23950K .......... .......... .......... .......... .......... 75%  283M 0s\n 24000K .......... .......... .......... .......... .......... 75%  418M 0s\n 24050K .......... .......... .......... .......... .......... 75%  328M 0s\n 24100K .......... .......... .......... .......... .......... 75%  383M 0s\n 24150K .......... .......... .......... .......... .......... 75%  369M 0s\n 24200K .......... .......... .......... .......... .......... 75%  339M 0s\n 24250K .......... .......... .......... .......... .......... 76%  431M 0s\n 24300K .......... .......... .......... .......... .......... 76%  436M 0s\n 24350K .......... .......... .......... .......... .......... 76%  300M 0s\n 24400K .......... .......... .......... .......... .......... 76%  445M 0s\n 24450K .......... .......... .......... .......... .......... 76%  356M 0s\n 24500K .......... .......... .......... .......... .......... 76%  372M 0s\n 24550K .......... .......... .......... .......... .......... 77%  274M 0s\n 24600K .......... .......... .......... .......... .......... 77%  307M 0s\n 24650K .......... .......... .......... .......... .......... 77%  404M 0s\n 24700K .......... .......... .......... .......... .......... 77%  429M 0s\n 24750K .......... .......... .......... .......... .......... 77%  323M 0s\n 24800K .......... .......... .......... .......... .......... 77% 74.4M 0s\n 24850K .......... .......... .......... .......... .......... 77% 49.0M 0s\n 24900K .......... .......... .......... .......... .......... 78%  321M 0s\n 24950K .......... .......... .......... .......... .......... 78%  294M 0s\n 25000K .......... .......... .......... .......... .......... 78%  406M 0s\n 25050K .......... .......... .......... .......... .......... 78%  120M 0s\n 25100K .......... .......... .......... .......... .......... 78%  426M 0s\n 25150K .......... .......... .......... .......... .......... 78%  219M 0s\n 25200K .......... .......... .......... .......... .......... 79%  262M 0s\n 25250K .......... .......... .......... .......... .......... 79%  403M 0s\n 25300K .......... .......... .......... .......... .......... 79%  390M 0s\n 25350K .......... .......... .......... .......... .......... 79%  370M 0s\n 25400K .......... .......... .......... .......... .......... 79%  329M 0s\n 25450K .......... .......... .......... .......... .......... 79%  279M 0s\n 25500K .......... .......... .......... .......... .......... 79%  406M 0s\n 25550K .......... .......... .......... .......... .......... 80%  288M 0s\n 25600K .......... .......... .......... .......... .......... 80%  340M 0s\n 25650K .......... .......... .......... .......... .......... 80%  315M 0s\n 25700K .......... .......... .......... .......... .......... 80%  430M 0s\n 25750K .......... .......... .......... .......... .......... 80%  304M 0s\n 25800K .......... .......... .......... .......... .......... 80%  251M 0s\n 25850K .......... .......... .......... .......... .......... 81%  377M 0s\n 25900K .......... .......... .......... .......... .......... 81%  348M 0s\n 25950K .......... .......... .......... .......... .......... 81%  325M 0s\n 26000K .......... .......... .......... .......... .......... 81%  365M 0s\n 26050K .......... .......... .......... .......... .......... 81%  328M 0s\n 26100K .......... .......... .......... .......... .......... 81%  380M 0s\n 26150K .......... .......... .......... .......... .......... 82%  268M 0s\n 26200K .......... .......... .......... .......... .......... 82%  319M 0s\n 26250K .......... .......... .......... .......... .......... 82%  396M 0s\n 26300K .......... .......... .......... .......... .......... 82%  315M 0s\n 26350K .......... .......... .......... .......... .......... 82%  276M 0s\n 26400K .......... .......... .......... .......... .......... 82%  288M 0s\n 26450K .......... .......... .......... .......... .......... 82%  432M 0s\n 26500K .......... .......... .......... .......... .......... 83%  330M 0s\n 26550K .......... .......... .......... .......... .......... 83%  387M 0s\n 26600K .......... .......... .......... .......... .......... 83%  100M 0s\n 26650K .......... .......... .......... .......... .......... 83% 53.8M 0s\n 26700K .......... .......... .......... .......... .......... 83%  305M 0s\n 26750K .......... .......... .......... .......... .......... 83%  171M 0s\n 26800K .......... .......... .......... .......... .......... 84%  345M 0s\n 26850K .......... .......... .......... .......... .......... 84%  171M 0s\n 26900K .......... .......... .......... .......... .......... 84%  316M 0s\n 26950K .......... .......... .......... .......... .......... 84%  231M 0s\n 27000K .......... .......... .......... .......... .......... 84%  247M 0s\n 27050K .......... .......... .......... .......... .......... 84%  376M 0s\n 27100K .......... .......... .......... .......... .......... 85%  280M 0s\n 27150K .......... .......... .......... .......... .......... 85%  288M 0s\n 27200K .......... .......... .......... .......... .......... 85%  357M 0s\n 27250K .......... .......... .......... .......... .......... 85%  395M 0s\n 27300K .......... .......... .......... .......... .......... 85%  286M 0s\n 27350K .......... .......... .......... .......... .......... 85%  415M 0s\n 27400K .......... .......... .......... .......... .......... 85%  349M 0s\n 27450K .......... .......... .......... .......... .......... 86%  390M 0s\n 27500K .......... .......... .......... .......... .......... 86%  357M 0s\n 27550K .......... .......... .......... .......... .......... 86%  299M 0s\n 27600K .......... .......... .......... .......... .......... 86%  328M 0s\n 27650K .......... .......... .......... .......... .......... 86%  403M 0s\n 27700K .......... .......... .......... .......... .......... 86%  444M 0s\n 27750K .......... .......... .......... .......... .......... 87%  351M 0s\n 27800K .......... .......... .......... .......... .......... 87%  413M 0s\n 27850K .......... .......... .......... .......... .......... 87%  342M 0s\n 27900K .......... .......... .......... .......... .......... 87%  396M 0s\n 27950K .......... .......... .......... .......... .......... 87%  361M 0s\n 28000K .......... .......... .......... .......... .......... 87%  344M 0s\n 28050K .......... .......... .......... .......... .......... 87%  306M 0s\n 28100K .......... .......... .......... .......... .......... 88%  403M 0s\n 28150K .......... .......... .......... .......... .......... 88%  351M 0s\n 28200K .......... .......... .......... .......... .......... 88%  410M 0s\n 28250K .......... .......... .......... .......... .......... 88%  363M 0s\n 28300K .......... .......... .......... .......... .......... 88%  408M 0s\n 28350K .......... .......... .......... .......... .......... 88%  366M 0s\n 28400K .......... .......... .......... .......... .......... 89% 77.1M 0s\n 28450K .......... .......... .......... .......... .......... 89%  247M 0s\n 28500K .......... .......... .......... .......... .......... 89% 50.3M 0s\n 28550K .......... .......... .......... .......... .......... 89% 98.6M 0s\n 28600K .......... .......... .......... .......... .......... 89%  142M 0s\n 28650K .......... .......... .......... .......... .......... 89% 72.4M 0s\n 28700K .......... .......... .......... .......... .......... 90% 73.4M 0s\n 28750K .......... .......... .......... .......... .......... 90% 70.9M 0s\n 28800K .......... .......... .......... .......... .......... 90%  107M 0s\n 28850K .......... .......... .......... .......... .......... 90%  141M 0s\n 28900K .......... .......... .......... .......... .......... 90%  174M 0s\n 28950K .......... .......... .......... .......... .......... 90%  111M 0s\n 29000K .......... .......... .......... .......... .......... 90%  129M 0s\n 29050K .......... .......... .......... .......... .......... 91%  404M 0s\n 29100K .......... .......... .......... .......... .......... 91%  390M 0s\n 29150K .......... .......... .......... .......... .......... 91%  335M 0s\n 29200K .......... .......... .......... .......... .......... 91%  419M 0s\n 29250K .......... .......... .......... .......... .......... 91%  160M 0s\n 29300K .......... .......... .......... .......... .......... 91%  414M 0s\n 29350K .......... .......... .......... .......... .......... 92%  397M 0s\n 29400K .......... .......... .......... .......... .......... 92%  420M 0s\n 29450K .......... .......... .......... .......... .......... 92%  369M 0s\n 29500K .......... .......... .......... .......... .......... 92%  414M 0s\n 29550K .......... .......... .......... .......... .......... 92%  353M 0s\n 29600K .......... .......... .......... .......... .......... 92%  380M 0s\n 29650K .......... .......... .......... .......... .......... 92% 94.1M 0s\n 29700K .......... .......... .......... .......... .......... 93% 95.2M 0s\n 29750K .......... .......... .......... .......... .......... 93% 88.3M 0s\n 29800K .......... .......... .......... .......... .......... 93%  158M 0s\n 29850K .......... .......... .......... .......... .......... 93%  113M 0s\n 29900K .......... .......... .......... .......... .......... 93% 79.6M 0s\n 29950K .......... .......... .......... .......... .......... 93%  125M 0s\n 30000K .......... .......... .......... .......... .......... 94%  329M 0s\n 30050K .......... .......... .......... .......... .......... 94%  293M 0s\n 30100K .......... .......... .......... .......... .......... 94%  132M 0s\n 30150K .......... .......... .......... .......... .......... 94%  256M 0s\n 30200K .......... .......... .......... .......... .......... 94%  361M 0s\n 30250K .......... .......... .......... .......... .......... 94%  420M 0s\n 30300K .......... .......... .......... .......... .......... 95%  422M 0s\n 30350K .......... .......... .......... .......... .......... 95%  198M 0s\n 30400K .......... .......... .......... .......... .......... 95%  339M 0s\n 30450K .......... .......... .......... .......... .......... 95%  400M 0s\n 30500K .......... .......... .......... .......... .......... 95%  338M 0s\n 30550K .......... .......... .......... .......... .......... 95%  195M 0s\n 30600K .......... .......... .......... .......... .......... 95%  160M 0s\n 30650K .......... .......... .......... .......... .......... 96%  113M 0s\n 30700K .......... .......... .......... .......... .......... 96%  293M 0s\n 30750K .......... .......... .......... .......... .......... 96%  156M 0s\n 30800K .......... .......... .......... .......... .......... 96%  271M 0s\n 30850K .......... .......... .......... .......... .......... 96%  305M 0s\n 30900K .......... .......... .......... .......... .......... 96%  313M 0s\n 30950K .......... .......... .......... .......... .......... 97%  268M 0s\n 31000K .......... .......... .......... .......... .......... 97%  320M 0s\n 31050K .......... .......... .......... .......... .......... 97%  317M 0s\n 31100K .......... .......... .......... .......... .......... 97%  284M 0s\n 31150K .......... .......... .......... .......... .......... 97%  246M 0s\n 31200K .......... .......... .......... .......... .......... 97%  306M 0s\n 31250K .......... .......... .......... .......... .......... 98%  319M 0s\n 31300K .......... .......... .......... .......... .......... 98%  299M 0s\n 31350K .......... .......... .......... .......... .......... 98%  289M 0s\n 31400K .......... .......... .......... .......... .......... 98%  310M 0s\n 31450K .......... .......... .......... .......... .......... 98%  300M 0s\n 31500K .......... .......... .......... .......... .......... 98%  314M 0s\n 31550K .......... .......... .......... .......... .......... 98%  259M 0s\n 31600K .......... .......... .......... .......... .......... 99%  318M 0s\n 31650K .......... .......... .......... .......... .......... 99%  274M 0s\n 31700K .......... .......... .......... .......... .......... 99%  291M 0s\n 31750K .......... .......... .......... .......... .......... 99%  280M 0s\n 31800K .......... .......... .......... .......... .......... 99%  310M 0s\n 31850K .......... .......... .......... .......... .......... 99%  310M 0s\n 31900K .......... .......... .......... .......              100%  279M=0.2s\n\n2023-10-17 14:56:32 (129 MB/s) - ‘/tmp/externals/cuda/libcusolver-dev-11-7_11.4.0.1-1_amd64.deb’ saved [32704192/32704192]\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libcurand-dev-11-7.\n(Reading database ... 101062 files and directories currently installed.)\nPreparing to unpack .../libcurand-dev-11-7_10.2.10.50-1_amd64.deb ...\nUnpacking libcurand-dev-11-7 (10.2.10.50-1) ...\nSetting up libcurand-dev-11-7 (10.2.10.50-1) ...\nSelecting previously unselected package libcusparse-dev-11-7.\n(Reading database ... 101086 files and directories currently installed.)\nPreparing to unpack .../libcusparse-dev-11-7_11.7.3.50-1_amd64.deb ...\nUnpacking libcusparse-dev-11-7 (11.7.3.50-1) ...\nSetting up libcusparse-dev-11-7 (11.7.3.50-1) ...\nSelecting previously unselected package libcublas-dev-11-7.\n(Reading database ... 101099 files and directories currently installed.)\nPreparing to unpack .../libcublas-dev-11-7_11.10.1.25-1_amd64.deb ...\nUnpacking libcublas-dev-11-7 (11.10.1.25-1) ...\nSetting up libcublas-dev-11-7 (11.10.1.25-1) ...\nSelecting previously unselected package libcusolver-dev-11-7.\n(Reading database ... 101121 files and directories currently installed.)\nPreparing to unpack .../libcusolver-dev-11-7_11.4.0.1-1_amd64.deb ...\nUnpacking libcusolver-dev-11-7 (11.4.0.1-1) ...\nSetting up libcusolver-dev-11-7 (11.4.0.1-1) ...\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "mkdir -p /tmp/externals/cuda\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcurand-dev-11-7_10.2.10.50-1_amd64.deb -P /tmp/externals/cuda\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcusparse-dev-11-7_11.7.3.50-1_amd64.deb -P /tmp/externals/cuda\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcublas-dev-11-7_11.10.1.25-1_amd64.deb -P /tmp/externals/cuda\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcusolver-dev-11-7_11.4.0.1-1_amd64.deb -P /tmp/externals/cuda\n",
    "\n",
    "dpkg -i /tmp/externals/cuda/libcurand-dev-11-7_10.2.10.50-1_amd64.deb\n",
    "dpkg -i /tmp/externals/cuda/libcusparse-dev-11-7_11.7.3.50-1_amd64.deb\n",
    "dpkg -i /tmp/externals/cuda/libcublas-dev-11-7_11.10.1.25-1_amd64.deb\n",
    "dpkg -i /tmp/externals/cuda/libcusolver-dev-11-7_11.4.0.1-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c107709a-786a-46d2-bca7-094d503a2b87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting deepspeed==0.9.1\n  Downloading deepspeed-0.9.1.tar.gz (766 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 766.2/766.2 kB 6.9 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting py-cpuinfo==9.0.0\n  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\nCollecting hjson\n  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.0/54.0 kB 10.7 MB/s eta 0:00:00\nCollecting ninja\n  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 11.5 MB/s eta 0:00:00\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from deepspeed==0.9.1) (1.21.5)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from deepspeed==0.9.1) (21.3)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.10/site-packages (from deepspeed==0.9.1) (5.9.0)\nRequirement already satisfied: pydantic<2.0.0 in /databricks/python3/lib/python3.10/site-packages (from deepspeed==0.9.1) (1.10.6)\nRequirement already satisfied: torch in /databricks/python3/lib/python3.10/site-packages (from deepspeed==0.9.1) (1.13.1+cu117)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from deepspeed==0.9.1) (4.64.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging>=20.0->deepspeed==0.9.1) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.10/site-packages (from pydantic<2.0.0->deepspeed==0.9.1) (4.3.0)\nBuilding wheels for collected packages: deepspeed\n  Building wheel for deepspeed (setup.py): started\n  Building wheel for deepspeed (setup.py): finished with status 'done'\n  Created wheel for deepspeed: filename=deepspeed-0.9.1-py3-none-any.whl size=798574 sha256=70233f207f2b78fa00da59fff57b3a21ffe205f8db19dd55f8c065e4aa3cd59c\n  Stored in directory: /root/.cache/pip/wheels/22/fb/58/11dd2b0b2490eaaea3708f4115ea6cdb702de5beccb512b478\nSuccessfully built deepspeed\nInstalling collected packages: py-cpuinfo, ninja, hjson, deepspeed\nSuccessfully installed deepspeed-0.9.1 hjson-3.1.0 ninja-1.11.1.1 py-cpuinfo-9.0.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install deepspeed==0.9.1 py-cpuinfo==9.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c47c4b00-0a3b-447f-a51a-1ba004344dfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| enumerating serving endpoints...found 0...(0 seconds)\n| removing the working directory \"dbfs:/mnt/dbacademy-users/odl_user_1125535@databrickslabs.com/large-language-models\"...(0 seconds)\n\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/large-language-models/v01\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing lab testing framework.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nUsing the \"default\" schema.\n\nPredefined paths variables:\n| DA.paths.working_dir: /dbfs/mnt/dbacademy-users/odl_user_1125535@databrickslabs.com/large-language-models\n| DA.paths.user_db:     /dbfs/mnt/dbacademy-users/odl_user_1125535@databrickslabs.com/large-language-models/database.db\n| DA.paths.datasets:    /dbfs/mnt/dbacademy-datasets/large-language-models/v01\n\nSetup completed (7 seconds)\n\nThe models developed or used in this course are for demonstration and learning purposes only.\nModels may occasionally output offensive, inaccurate, biased information, or harmful instructions.\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "335fea72-1dda-405e-af3d-64e372c8a041",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username:          odl_user_1125535@databrickslabs.com\nWorking Directory: /dbfs/mnt/dbacademy-users/odl_user_1125535@databrickslabs.com/large-language-models\n"
     ]
    }
   ],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dcf5219-278b-4654-a445-7e2d423d47ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfb26147-69e7-4bc0-8c88-ec0d5b385564",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Creating a local temporary directory on the Driver. This will serve as a root directory for the intermediate model checkpoints created during the training process. The final model will be persisted to DBFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5119758d-3ec0-428b-a513-52be21d6f2cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "tmpdir = tempfile.TemporaryDirectory()\n",
    "local_training_root = tmpdir.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "061df562-3fa8-44ac-bfef-28e6677ac74b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b290af9-5bdd-4115-960f-4ebbb33d270c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import transformers as tr\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec8e4517-285e-4c56-8693-d964476c5bf6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 1 - Data Preparation\n",
    "\n",
    "The first step of the fine-tuning process is to identify a specific task and supporting dataset. In this notebook, we will consider the specific task to be classifying movie reviews. This idea is generally simple task where a movie review is provided as plain-text and we would like to determine whether or not the review was positive or negative.\n",
    "\n",
    "The [IMDB dataset](https://huggingface.co/datasets/imdb) can be leveraged as a supporting dataset for this task. The dataset conveniently provides both a training and testing dataset with labeled binary sentiments, as well as a dataset of unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83318bde-5ed1-47db-8ed9-1d22b9bbaf4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:27: UserWarning: This dataset can not be stored in DBFS because either `cache_dir` or the environment variable `HF_DATASETS_CACHE` is set to a non-DBFS path. If this cluster restarts, all saved dataset information will be lost.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0035b4d7de6c4d79a3aee6904329bb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22841a35e1f4aa0b507fa311fc02d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c036c0637984dc1a43fb6a6ff4a9e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:13: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6946134271a403382e98277dae7b7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8759a0435ab4c8b91a784d9a48cbff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a7ccecd1614044a280ad0e5b550ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7481a192ed2b4cbd8129e1ee44089fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693ff8163be145cf91d62e31753ebc16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_ds = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "177a0b50-66fb-42c3-91ad-99ddaeedd59f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 2 - Select pre-trained model\n",
    "\n",
    "The next step of the fine-tuning process is to select a pre-trained model. We will consider using the [T5](https://huggingface.co/docs/transformers/model_doc/t5) [[paper]](https://arxiv.org/pdf/1910.10683.pdf) family of models for our fine-tuning purposes. The T5 models are text-to-text transformers that have been trained on a multi-task mixture of unsupervised and supervised tasks. They are well suited for tasks such as summarization, translation, text classification, question answering, and more.\n",
    "\n",
    "The `t5-small` version of the T5 models has 60 million parameters. This slimmed down version will be sufficient for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "994ccabd-c773-4d73-8bc3-f33e18161481",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26e55a62-8a9b-4c0e-baa9-5ec4b739c2fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Recall from Module 1, Hugging Face provides the [Auto*](https://huggingface.co/docs/transformers/model_doc/auto) suite of objects to conveniently instantiate the various components associated with a pre-trained model. Here, we use the [AutoTokenizer](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer) to load in the tokenizer that is associated with the `t5-small` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa8fd5e0-b64c-454c-a152-34b961333a3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the tokenizer that was used for the t5-small model\n",
    "tokenizer = tr.AutoTokenizer.from_pretrained(\n",
    "    model_checkpoint, cache_dir=DA.paths.datasets\n",
    ")  # Use a pre-cached model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b74aa87-06d4-4bb2-971f-0981e7f5c65a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "As mentioned above, the IMDB dataset is a binary sentiment dataset. Its labels therefore are encoded as (-1 - unknown; 0 - negative; 1 - positive) values. In order to use this dataset with a text-to-text model like T5, the label set needs to be represented as a string. There are a number of ways to accomplish this. Here, we will simply translate each label id to its corresponding string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83a9eb90-eb8e-4c56-91d1-1ff8d7189c19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_tokens(\n",
    "    tokenizer: tr.models.t5.tokenization_t5_fast.T5TokenizerFast, label_map: dict\n",
    ") -> callable:\n",
    "    \"\"\"\n",
    "    Given a `tokenizer` this closure will iterate through `x` and return the result of `apply()`.\n",
    "    This function is mapped to a dataset and returned with ids and attention mask.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(x) -> tr.tokenization_utils_base.BatchEncoding:\n",
    "        \"\"\"From a formatted dataset `x` a batch encoding `token_res` is created.\"\"\"\n",
    "        target_labels = [label_map[y] for y in x[\"label\"]]\n",
    "        token_res = tokenizer(\n",
    "            x[\"text\"],\n",
    "            text_target=target_labels,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "        )\n",
    "        return token_res\n",
    "\n",
    "    return apply\n",
    "\n",
    "\n",
    "imdb_label_lookup = {0: \"negative\", 1: \"positive\", -1: \"unknown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4cf368b-103a-449d-ad51-b890e817a4ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b85192e09e44b590a8d57a371b1038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef79bff867bb479b923be2f23a443d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a812fe5579a4482784504d8df5d0e01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_to_tokens = to_tokens(tokenizer, imdb_label_lookup)\n",
    "tokenized_dataset = imdb_ds.map(\n",
    "    imdb_to_tokens, batched=True, remove_columns=[\"text\", \"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9906c4ab-b671-411f-8710-44e32c8978a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 3 - Setup Training\n",
    "\n",
    "The model training process is highly configurable. The [TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments) class effectively exposes the configurable aspects of the process allowing one to customize them accordingly. Here, we will focus on setting up a training process that performs a single epoch of training with a batch size of 16. We will also leverage `adamw_torch` as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e83dab1-8c95-4750-9776-572c26a54337",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_name = \"test-trainer\"\n",
    "local_checkpoint_path = os.path.join(local_training_root, checkpoint_name)\n",
    "training_args = tr.TrainingArguments(\n",
    "    local_checkpoint_path,\n",
    "    num_train_epochs=1,  # default number of epochs to train is 3\n",
    "    per_device_train_batch_size=16,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=[\"tensorboard\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9269057a-25cc-4574-95a3-de013e42c16c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The pre-trained `t5-small` model can be loaded using the [AutoModelForSeq2SeqLM](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSeq2SeqLM) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2084171a-9f03-438f-91d6-e092f63b8d42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the pre-trained model\n",
    "model = tr.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_checkpoint, cache_dir=DA.paths.datasets\n",
    ")  # Use a pre-cached model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30b45fb1-61fd-4ae9-adf2-fee3eaf98dee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+torch_distributed_hint": "",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# used to assist the trainer in batching the data\n",
    "data_collator = tr.DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = tr.Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6669f56-f17b-4001-a0ea-acb6c5c89f9f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 4 - Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0809fa7-0368-415e-a9cc-68b7898a636f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Before starting the training process, let's turn on Tensorboard. This will allow us to monitor the training process as checkpoint logs are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89594ab5-31b4-4a8c-8f31-31ffa9ba0694",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tensorboard_display_dir = f\"{local_checkpoint_path}/runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db4f551e-7088-42b7-9575-1e52ded4ef1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your log directory might be ephemeral to the cluster, which will be deleted after cluster termination or restart. You can choose a log directory under `/dbfs/` to persist your logs in DBFS.\nTensorboard may not be displayed in the notebook cell output when 'Third-party iFraming prevention' is disabled. You can still use Tensorboard by clicking the link below to open Tensorboard in a new tab. To enable Tensorboard in notebook cell output, please ask your workspace admin to enable 'Third-party iFraming prevention'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin-bottom: 16px\">\n",
       "            <a href=\"/driver-proxy/o/2266828816816743/1017-084817-budlne0i/6006/\">\n",
       "                Open in a new tab\n",
       "            </a>\n",
       "            <span style=\"margin-left: 1em; color: #a3a3a3\">Note: TensorBoard is only available when this notebook remains attached to the cluster.</span>\n",
       "        </div>\n",
       "        <div style=\"margin-bottom: 16px\">\n",
       "            <span style=\"color: #a3a3a3\">Note: This cell needs to be re-run for TensorBoard to be available if this notebook is imported into a different workspace.</span>\n",
       "        </div>\n",
       "        <iframe id=\"%tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\" src=\"/driver-proxy/o/2266828816816743/1017-084817-budlne0i/6006/\"></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '{tensorboard_display_dir}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32f6206c-1faa-4222-82fc-a75dd265138d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Start the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f6a61d-57bd-402c-910f-6721254e1b5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 04:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.127600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# save model to the local checkpoint\n",
    "trainer.save_model()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec182f54-d483-48f7-b2a0-5cf2118c1d99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# persist the fine-tuned model to DBFS\n",
    "final_model_path = f\"{DA.paths.working_dir}/llm04_fine_tuning/{checkpoint_name}\"\n",
    "trainer.save_model(output_dir=final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82adbef6-325d-457f-b93f-5229354b57da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 5 - Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13fe7ca7-5a81-4fb0-a082-e8bcdcc940ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fine_tuned_model = tr.AutoModelForSeq2SeqLM.from_pretrained(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f11af3b1-75ed-4104-8a9f-1812a2497efd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reviews = [\n",
    "    \"\"\"\n",
    "'Despicable Me' is a cute and funny movie, but the plot is predictable and the characters are not very well-developed. Overall, it's a good movie for kids, but adults might find it a bit boring.\"\"\",\n",
    "    \"\"\" 'The Batman' is a dark and gritty take on the Caped Crusader, starring Robert Pattinson as Bruce Wayne. The film is a well-made crime thriller with strong performances and visuals, but it may be too slow-paced and violent for some viewers.\n",
    "\"\"\",\n",
    "    \"\"\"\n",
    "The Phantom Menace is a visually stunning film with some great action sequences, but the plot is slow-paced and the dialogue is often wooden. It is a mixed bag that will appeal to some fans of the Star Wars franchise, but may disappoint others.\n",
    "\"\"\",\n",
    "    \"\"\"\n",
    "I'm not sure if The Matrix and the two sequels were meant to have a tigh consistency but I don't think they quite fit together. They seem to have a reasonably solid arc but the features from the first aren't in the second and third as much, instead the second and third focus more on CGI battles and more visuals. I like them but for different reasons, so if I'm supposed to rate the trilogy I'm not sure what to say.\n",
    "\"\"\",\n",
    "]\n",
    "inputs = tokenizer(reviews, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "pred = fine_tuned_model.generate(\n",
    "    input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beb7474a-9831-41a9-b05d-f882c6fe8066",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>review</th><th>classification</th></tr></thead><tbody><tr><td>\n",
       "'Despicable Me' is a cute and funny movie, but the plot is predictable and the characters are not very well-developed. Overall, it's a good movie for kids, but adults might find it a bit boring.</td><td>negative</td></tr><tr><td> 'The Batman' is a dark and gritty take on the Caped Crusader, starring Robert Pattinson as Bruce Wayne. The film is a well-made crime thriller with strong performances and visuals, but it may be too slow-paced and violent for some viewers.\n",
       "</td><td>positive</td></tr><tr><td>\n",
       "The Phantom Menace is a visually stunning film with some great action sequences, but the plot is slow-paced and the dialogue is often wooden. It is a mixed bag that will appeal to some fans of the Star Wars franchise, but may disappoint others.\n",
       "</td><td>positive</td></tr><tr><td>\n",
       "I'm not sure if The Matrix and the two sequels were meant to have a tigh consistency but I don't think they quite fit together. They seem to have a reasonably solid arc but the features from the first aren't in the second and third as much, instead the second and third focus more on CGI battles and more visuals. I like them but for different reasons, so if I'm supposed to rate the trilogy I'm not sure what to say.\n",
       "</td><td>negative</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "\n'Despicable Me' is a cute and funny movie, but the plot is predictable and the characters are not very well-developed. Overall, it's a good movie for kids, but adults might find it a bit boring.",
         "negative"
        ],
        [
         " 'The Batman' is a dark and gritty take on the Caped Crusader, starring Robert Pattinson as Bruce Wayne. The film is a well-made crime thriller with strong performances and visuals, but it may be too slow-paced and violent for some viewers.\n",
         "positive"
        ],
        [
         "\nThe Phantom Menace is a visually stunning film with some great action sequences, but the plot is slow-paced and the dialogue is often wooden. It is a mixed bag that will appeal to some fans of the Star Wars franchise, but may disappoint others.\n",
         "positive"
        ],
        [
         "\nI'm not sure if The Matrix and the two sequels were meant to have a tigh consistency but I don't think they quite fit together. They seem to have a reasonably solid arc but the features from the first aren't in the second and third as much, instead the second and third focus more on CGI battles and more visuals. I like them but for different reasons, so if I'm supposed to rate the trilogy I'm not sure what to say.\n",
         "negative"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "review",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "classification",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf = pd.DataFrame(\n",
    "    zip(reviews, tokenizer.batch_decode(pred, skip_special_tokens=True)),\n",
    "    columns=[\"review\", \"classification\"],\n",
    ")\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d783534b-b1ef-4141-9acf-f025c3a9cbc4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## DeepSpeed\n",
    "\n",
    "As model architectures evolve and grow, they continually push the limits of available computational resources. For example, some large LLMs having hundreds of billions of parameters making them too large to fit, in some cases, in available GPU memory. Models of this scale therefore need to leverage distributed processing or high-end hardware, and sometimes even both, to support training efforts. This makes large model training a costly undertaking, and therefore accelerating the training process is highly desirable.\n",
    "\n",
    "As mentioned above, one such framework that can be leveraged to accelerate the model training process is Microsoft's [DeepSpeed](https://github.com/microsoft/DeepSpeed) [[paper]](https://arxiv.org/pdf/2207.00032.pdf). This framework provides advances in compression, distributed training, mixed precision, gradient accumulation, and checkpointing.\n",
    "\n",
    "It is worth noting that DeepSpeed is intended for large models that do not fit into device memory. The `t5-base` model we are using is not a large model, and therefore DeepSpeed is not expected to provide a benefit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2d773ae-f9bb-4cd2-8f41-b2596f27dc24",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Environment Setup\n",
    "\n",
    "The intended use for DeepSpeed is in a distributed compute environment. As such, each node of the environment is assigned a `rank` and `local_rank` in relation to the size of the distributed environment.\n",
    "\n",
    "Here, since we are testing with a single node/GPU environment we will set the `world_size` to 1, and both `ranks` to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaea8388-2d10-4fe7-a318-59da284afd3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9994\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7224823b-191a-4b7c-b0be-3f2838103597",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Configuration\n",
    "\n",
    "There are a number of [configuration options](https://www.deepspeed.ai/docs/config-json/) that can be set to enhance the training and inference processes. The [ZeRO optimization](https://www.deepspeed.ai/training/#memory-efficiency) settings target reducing the memory footprint allowing for larger models to be efficiently trained on limited resources. \n",
    "\n",
    "The Hugging Face `TrainerArguments` accept the configuration either from a JSON file or a dictionary. Here, we will define the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fce8e31-d01b-416b-9f22-bdd036e24291",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "zero_config = {\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 2,\n",
    "        \"offload_optimizer\": {\"device\": \"cpu\", \"pin_memory\": True},\n",
    "        \"allgather_partitions\": True,\n",
    "        \"allgather_bucket_size\": 5e8,\n",
    "        \"overlap_comm\": True,\n",
    "        \"reduce_scatter\": True,\n",
    "        \"reduce_bucket_size\": 5e8,\n",
    "        \"contiguous_gradients\": True,\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\",\n",
    "            \"torch_adam\": True,\n",
    "        },\n",
    "    },\n",
    "    \"train_batch_size\": \"auto\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c79c4d-a9f4-4480-84a7-b9d6cc9a054b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d8af12e646418bbdcf064185700fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39deab822aa34947b3cc66ccc90feab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b30ee5f033a47448baf17acd158098b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_checkpoint = \"t5-base\"\n",
    "tokenizer = tr.AutoTokenizer.from_pretrained(\n",
    "    model_checkpoint, cache_dir=DA.paths.datasets\n",
    ")\n",
    "\n",
    "imdb_to_tokens = to_tokens(tokenizer, imdb_label_lookup)\n",
    "tokenized_dataset = imdb_ds.map(\n",
    "    imdb_to_tokens, batched=True, remove_columns=[\"text\", \"label\"]\n",
    ")\n",
    "\n",
    "model = tr.AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_checkpoint, cache_dir=DA.paths.datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "212761c7-c77a-4948-8681-53a192168adc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93d4d41c-cfa9-41d2-821d-a70d1db78703",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "There are only two changes made to the training setup from above. The first is to set a new checkpoint name. The second is to add the `deepspeed` configuration to the `TrainingArguments`.\n",
    "\n",
    "Note: at this time the `deepspeed` argument is considered an experimental feature and may evolve in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac33e6b4-fc24-4550-8796-bd065694991b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_name = \"test-trainer-deepspeed\"\n",
    "checkpoint_location = os.path.join(local_training_root, checkpoint_name)\n",
    "training_args = tr.TrainingArguments(\n",
    "    checkpoint_location,\n",
    "    num_train_epochs=3,  # default number of epochs to train is 3\n",
    "    per_device_train_batch_size=8,\n",
    "    deepspeed=zero_config,  # add the deepspeed configuration\n",
    "    report_to=[\"tensorboard\"],\n",
    ")\n",
    "\n",
    "data_collator = tr.DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = tr.Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bc75481-88e5-4dd3-afd8-e9bfdf5617cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tensorboard_display_dir = f\"{checkpoint_location}/runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8e47bf-8faf-4197-9e56-d38ad6e2b62d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\nYour log directory might be ephemeral to the cluster, which will be deleted after cluster termination or restart. You can choose a log directory under `/dbfs/` to persist your logs in DBFS.\nTensorboard may not be displayed in the notebook cell output when 'Third-party iFraming prevention' is disabled. You can still use Tensorboard by clicking the link below to open Tensorboard in a new tab. To enable Tensorboard in notebook cell output, please ask your workspace admin to enable 'Third-party iFraming prevention'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin-bottom: 16px\">\n",
       "            <a href=\"/driver-proxy/o/2266828816816743/1017-084817-budlne0i/6007/\">\n",
       "                Open in a new tab\n",
       "            </a>\n",
       "            <span style=\"margin-left: 1em; color: #a3a3a3\">Note: TensorBoard is only available when this notebook remains attached to the cluster.</span>\n",
       "        </div>\n",
       "        <div style=\"margin-bottom: 16px\">\n",
       "            <span style=\"color: #a3a3a3\">Note: This cell needs to be re-run for TensorBoard to be available if this notebook is imported into a different workspace.</span>\n",
       "        </div>\n",
       "        <iframe id=\"%tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\" src=\"/driver-proxy/o/2266828816816743/1017-084817-budlne0i/6007/\"></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '{tensorboard_display_dir}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "142412a4-c1c3-43e7-8f83-7da605694312",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\nCreating extension directory /root/.cache/torch_extensions/py310_cu117/utils...\nEmitting ninja build file /root/.cache/torch_extensions/py310_cu117/utils/build.ninja...\nBuilding extension module utils...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nLoading extension module utils...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load utils op: 14.725844621658325 seconds\nRank: 0 partition count [1] and sizes[(222903552, False)] \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\nNo modifications detected for re-loaded extension module utils, skipping build step...\nLoading extension module utils...\nYou're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load utils op: 0.0006234645843505859 seconds\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/torch/nn/modules/module.py:1432: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.save_model()\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "352b3213-94d3-4b99-a246-600d4ce7669f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# persist the fine-tuned model to DBFS\n",
    "final_model_path = f\"{DA.paths.working_dir}/llm04_fine_tuning/{checkpoint_name}\"\n",
    "trainer.save_model(output_dir=final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ae4dd6d-69e3-4d79-a32f-ff4e846d5bff",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "692665e2-473d-4778-b8e6-f905097d7a26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fine_tuned_model = tr.AutoModelForSeq2SeqLM.from_pretrained(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd20463e-3d40-4847-9aee-f90e5cb99696",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "review = [\n",
    "    \"\"\"\n",
    "           I'm not sure if The Matrix and the two sequels were meant to have a tight consistency but I don't think they quite fit together. They seem to have a reasonably solid arc but the features from the first aren't in the second and third as much, instead the second and third focus more on CGI battles and more visuals. I like them but for different reasons, so if I'm supposed to rate the trilogy I'm not sure what to say.\"\"\"\n",
    "]\n",
    "inputs = tokenizer(review, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "pred = fine_tuned_model.generate(\n",
    "    input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55a985c3-fd8c-4d16-8269-03acb57d7cec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf = pd.DataFrame(\n",
    "    zip(review, tokenizer.batch_decode(pred, skip_special_tokens=True)),\n",
    "    columns=[\"review\", \"classification\"],\n",
    ")\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54a2488f-daf9-4e14-9ba7-397dbab988bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Clean up Classroom\n",
    "\n",
    "Run the following cell to remove lessons-specific assets created during this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "633e4baa-865a-46d8-b61a-c69726fce3b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dda5dd0-e872-4e09-8a5e-8a21e8aedd38",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 465486717961795,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "LLM 04a - Fine-tuning LLMs",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
